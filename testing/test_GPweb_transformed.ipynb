{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import gp_grief\n",
    "from scipy.stats import multivariate_normal as mvn #.logpdf\n",
    "from scipy.stats import chi2\n",
    "import pymcmc as pm\n",
    "from numpy.testing import *\n",
    "from pdb import set_trace\n",
    "gp_grief.debug()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initialize the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.random.seed(0)\n",
    "X = np.random.randn(100, 4)\n",
    "X[:, 0] = 1. # Intercept column.\n",
    "Y = np.dot(X, [0.5, 0.1, 0.25, 1.]) + 0.1 * np.random.randn(X.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check the log-likelihood value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 14:27:04 ] gp_grief.models DEBUG: Initializing GPweb_transformed model.\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(0)\n",
    "m = gp_grief.models.GPweb_transformed(Phi=X, y=Y)\n",
    "tmp = np.random.rand(*m.parameters.shape) + 1e-6\n",
    "m.parameters = tmp\n",
    "ll_gpweb = m.log_likelihood()\n",
    "\n",
    "# now compute manually\n",
    "w = m.kern.parameters.reshape((1,-1))\n",
    "sig2 = m.noise_var\n",
    "Phit = np.linalg.svd(X, full_matrices=False, compute_uv=True)[0]\n",
    "K = Phit.dot(np.diag(w.squeeze()).dot(Phit.T)) + sig2*np.identity(Phit.shape[0])\n",
    "ll_exact = mvn.logpdf(Y.squeeze(), mean=np.zeros(Phit.shape[0]), cov=K)\n",
    "\n",
    "assert_array_almost_equal(ll_gpweb, ll_exact)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "check the log likelihood-gradients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 14:27:04 ] gp_grief.models INFO: Gradient check passed.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m.checkgrad()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "now wrap in pymcmc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "GPweb_transformed Model\n",
      "| Name      |    Value | Constraint   |\n",
      "|-----------+----------+--------------|\n",
      "| noise_var | 0.548815 | +ve          |\n",
      "<gp_grief.kern.WEBKernel object at 0x7fe32c187d90>\n",
      "Printing the transformed parameters:\n",
      "[-0.31306898  0.04361093 -0.18975376 -0.32239961 -0.63953869]\n",
      "[ 14:27:04 ] gp_grief.models INFO: Gradient check passed.\n"
     ]
    }
   ],
   "source": [
    "mcm = gp_grief.models.PyMCMC_Wrapper(m)\n",
    "print mcm\n",
    "print \"Printing the transformed parameters:\"\n",
    "print mcm.params \n",
    "\n",
    "# perform the check\n",
    "mcm.checkgrad()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "and now sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "# # Pick a proposal for MCMC (here we pick a Metropolized Langevin Proposal\n",
    "# proposal = pm.MALAProposal()\n",
    "# # Construct a Metropolis Hastings object\n",
    "# mcmc = pm.MetropolisHastings(mcm, # The model you want to train\n",
    "#               proposal=proposal,         # The proposal you want to use\n",
    "#               db_filename=None)#'demo_1_db.h5')# The HDF5 database to write the results\n",
    "# # Now we can sample it:\n",
    "# iters = 10000\n",
    "# n_thin = int(max(50,   iters//1000)) # save at most 1000 samples\n",
    "# n_burn = int(max(1000, iters//10)) # burn no less than 10% of the total samples\n",
    "# print(\"running MCMC. n_sample=%d, n_thin=%d, n_burn=%d\"%(iters,n_thin,n_burn))\n",
    "# chain = mcmc.sample(int(iters),         # Number of MCMC steps\n",
    "#         num_thin=n_thin,  # Number of steps to skip\n",
    "#         num_burn=n_burn,  # Number of steps to burn initially\n",
    "#         verbose=True)   # Be verbose or not\n",
    "# print \"final sampled basis fun weight stats: min=%.4g, max=%.4g, ptp=%.4g, mean=%.4g, std=%.4g\" % \\\n",
    "#     tuple([fcn(chain[:,1:]) for fcn in [np.min, np.max, np.ptp, np.mean, np.std]])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
